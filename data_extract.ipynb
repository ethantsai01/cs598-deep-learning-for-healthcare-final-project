{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOFKoZVUuxyWgoZuYoRcJZm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"sh7T7R_3Od7S"},"outputs":[],"source":["import requests\n","from bs4 import BeautifulSoup\n","import os\n","import getpass\n","from tqdm import tqdm\n","\n","# Helper to clean folder/file names\n","def clean_name(name):\n","    return name.split('#')[0].split('?')[0].strip('/')\n","\n","# Login credentials\n","physio_username = input(\"PhysioNet username: \")\n","physio_password = getpass.getpass(\"PhysioNet password: \")\n","\n","login_url = \"https://physionet.org/login/\"\n","base_url = \"https://physionet.org/content/mimic-cxr/2.1.0/files/p10/\"\n","local_base = \"/content/mimic-cxr-p10\"\n","os.makedirs(local_base, exist_ok=True)\n","\n","# Start a session\n","session = requests.Session()\n","\n","# Step 1: Get CSRF token\n","login_page = session.get(login_url)\n","soup = BeautifulSoup(login_page.text, 'html.parser')\n","csrf_token = soup.find('input', {'name': 'csrfmiddlewaretoken'}).get('value')\n","\n","# Step 2: Post login data\n","login_data = {\n","    'username': physio_username,\n","    'password': physio_password,\n","    'csrfmiddlewaretoken': csrf_token,\n","    'next': '/'\n","}\n","headers = {'Referer': login_url}\n","\n","# Perform login\n","login_response = session.post(login_url, data=login_data, headers=headers)\n","if login_response.url == \"https://physionet.org/\":\n","    print(\"✅ Login successful!\")\n","else:\n","    print(\"❌ Login failed. Check your credentials or DUA acceptance.\")\n","    raise SystemExit()\n","\n","# Step 3: Fetch patient folders in p10\n","response = session.get(base_url)\n","soup = BeautifulSoup(response.content, 'html.parser')\n","patient_folders = [clean_name(a['href']) for a in soup.select(\"a[href^='p10']\")]\n","\n","print(f\"Found {len(patient_folders)} patient folders.\")\n","\n","# Step 4: Download only .txt files directly under patient folders\n","for patient in tqdm(patient_folders, desc=\"Patients\"):\n","    patient_folder_url = f\"{base_url}{patient}/\"\n","    local_patient_path = os.path.join(local_base, patient)\n","    os.makedirs(local_patient_path, exist_ok=True)\n","\n","    r = session.get(patient_folder_url)\n","    s = BeautifulSoup(r.content, 'html.parser')\n","\n","    # Download .txt files directly under patient folder (ignore subfolders)\n","    txt_files = [clean_name(a['href']) for a in s.select(\"a[href$='.txt']\")]\n","    for txt_file in txt_files:\n","        file_url = f\"{patient_folder_url}{txt_file}\"\n","        file_path = os.path.join(local_patient_path, txt_file)\n","        if not os.path.exists(file_path):\n","            print(f\"⬇️ Downloading {file_path}...\")\n","            with session.get(file_url, stream=True) as resp:\n","                total_size = int(resp.headers.get('content-length', 0))\n","                with open(file_path, 'wb') as f, tqdm(\n","                    desc=txt_file,\n","                    total=total_size,\n","                    unit='B',\n","                    unit_scale=True,\n","                    unit_divisor=1024\n","                ) as bar:\n","                    for chunk in resp.iter_content(chunk_size=8192):\n","                        f.write(chunk)\n","                        bar.update(len(chunk))\n","        else:\n","            print(f\"⚠️ {txt_file} already exists, skipping.\")\n"]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","\n","# Base directory\n","base_dir = '/content/mimic-cxr-p10'\n","\n","# Prepare list to hold rows\n","data = []\n","\n","# Walk through the directory\n","for patient_id in os.listdir(base_dir):\n","    patient_path = os.path.join(base_dir, patient_id)\n","    if os.path.isdir(patient_path):\n","        for file in os.listdir(patient_path):\n","            if file.endswith('.txt'):\n","                study_id = file.replace('.txt', '')\n","                txt_path = os.path.join(patient_path, file)\n","                with open(txt_path, 'r', encoding='utf-8') as f:\n","                    text = f.read()\n","                data.append({\n","                    'patient_id': patient_id,\n","                    'study_id': study_id,\n","                    'text': text\n","                })\n","\n","# Create DataFrame\n","df = pd.DataFrame(data)\n","\n","# Export to CSV\n","output_csv = 'mimic_reports.csv'\n","df.to_csv(output_csv, index=False)\n","\n","print(f\"Exported {len(df)} rows to {output_csv}\")\n"],"metadata":{"id":"uOk5R7RzOi4_"},"execution_count":null,"outputs":[]}]}